{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4ick84lFFZw",
        "outputId": "5e80e118-913f-4455-d788-a81996c535f6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/zllrunning/face-parsing.PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jEuHdbvFTva"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./face-parsing.PyTorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMpAPFgXFMT9",
        "outputId": "2163d58d-50f9-4a99-933b-4094dabad5ca"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812'\n",
        "output = 'weights.pth'  \n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDqVSy1OjyqV"
      },
      "outputs": [],
      "source": [
        "def vis_parsing_maps_for_video(im, parsing_anno, stride, grid_size):\n",
        "    part_colors = [[0, 0, 0] for i in range(24)]\n",
        "\n",
        "    # red skin\n",
        "    part_colors[0] = [0, 0, 175]\n",
        "    part_colors[6] = [0, 0, 175]\n",
        "    part_colors[7] = [0, 0, 175]\n",
        "    part_colors[9] = [0, 0, 175]\n",
        "    part_colors[13] = [0, 0, 175]\n",
        "\n",
        "    #red lips\n",
        "    part_colors[11] = [0, 0, 175]\n",
        "    part_colors[12] = [0, 0, 175]\n",
        "\n",
        "    #blue background\n",
        "    part_colors[23] = [255, 0, 0]\n",
        "\n",
        "\n",
        "    im = np.array(im)\n",
        "    vis_im = im.copy().astype(np.uint8)\n",
        "    original_vis_im = vis_im.copy()\n",
        "    vis_parsing_anno = parsing_anno.copy().astype(np.uint8)\n",
        "    vis_parsing_anno = cv2.resize(vis_parsing_anno, None, fx=stride, fy=stride, interpolation=cv2.INTER_NEAREST)\n",
        "    vis_parsing_anno_color = np.zeros((vis_parsing_anno.shape[0], vis_parsing_anno.shape[1], 3)) + 255\n",
        "\n",
        "    num_of_class = np.max(vis_parsing_anno)\n",
        "\n",
        "    for pi in range(1, num_of_class + 1):\n",
        "        index = np.where(vis_parsing_anno == pi)\n",
        "        vis_parsing_anno_color[index[0], index[1], :] = part_colors[pi]\n",
        "\n",
        "    h, w = vis_parsing_anno.shape\n",
        "    h_step = h // grid_size\n",
        "    w_step = w // grid_size\n",
        "\n",
        "    r = np.zeros_like(vis_parsing_anno).astype(np.uint8)\n",
        "    g = np.zeros_like(vis_parsing_anno).astype(np.uint8)\n",
        "    b = np.zeros_like(vis_parsing_anno).astype(np.uint8)\n",
        "\n",
        "    # Overlay diagonal grid lines and color them\n",
        "    for y in range(0, h-h_step, h_step):\n",
        "        for x in range(0, w-w_step, w_step):\n",
        "            # Diagonal from top-left to bottom-right of each cell\n",
        "            for d in range(min(h_step, w_step)):\n",
        "                segment = vis_parsing_anno[y+d, x+d]\n",
        "                dominant_label = segment\n",
        "                r[y+d, x+d] = part_colors[dominant_label - 1][0]\n",
        "                g[y+d, x+d] = part_colors[dominant_label - 1][1]\n",
        "                b[y+d, x+d] = part_colors[dominant_label - 1][2]\n",
        "\n",
        "            # Diagonal from top-right to bottom-left of each cell\n",
        "            for d in range(min(h_step, w_step)):\n",
        "                segment = vis_parsing_anno[y+d, x+w_step-d]\n",
        "                dominant_label = segment\n",
        "                r[y+d, x+w_step-d] = part_colors[dominant_label - 1][0]\n",
        "                g[y+d, x+w_step-d] = part_colors[dominant_label - 1][1]\n",
        "                b[y+d, x+w_step-d] = part_colors[dominant_label - 1][2]\n",
        "\n",
        "\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "\n",
        "    vis_im_bgr = cv2.cvtColor(cv2.cvtColor(vis_im, cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB)\n",
        "    weight_dis = 0.7\n",
        "    vis_im = cv2.addWeighted(vis_im_bgr, weight_dis, rgb, 1.0 - weight_dis, 0)\n",
        "\n",
        "    combined_image = np.hstack((original_vis_im, vis_im))\n",
        "\n",
        "    return combined_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsMRCtMVBrtk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def vis_parsing_maps_for_video(im, parsing_anno, stride, grid_size):\n",
        "    # Define part colors using a dictionary\n",
        "    part_colors = {\n",
        "        'skin': [0, 0, 175],\n",
        "        'lips': [0, 0, 175],\n",
        "        'background': [255, 0, 0],\n",
        "    }\n",
        "    color_map = [[0, 0, 0] for _ in range(24)]\n",
        "    for idx in [0, 6, 7, 9, 13, 11, 12]:  # skin and lips\n",
        "        color_map[idx] = part_colors['skin']\n",
        "    color_map[23] = part_colors['background']\n",
        "\n",
        "    vis_im = np.array(im, dtype=np.uint8)\n",
        "    original_vis_im = vis_im.copy()\n",
        "    vis_parsing_anno = cv2.resize(parsing_anno, None, fx=stride, fy=stride, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    vis_parsing_anno_color = np.array([color_map[val] for val in vis_parsing_anno.flat]).reshape(vis_parsing_anno.shape + (3,))\n",
        "\n",
        "    def overlay_diagonal(y, x, dy, dx):\n",
        "        for d in range(min(h_step, w_step)):\n",
        "            segment = vis_parsing_anno[y + d*dy, x + d*dx]\n",
        "            r[y + d*dy, x + d*dx], g[y + d*dy, x + d*dx], b[y + d*dy, x + d*dx] = color_map[segment - 1]\n",
        "\n",
        "    h, w = vis_parsing_anno.shape\n",
        "    h_step, w_step = h // grid_size, w // grid_size\n",
        "\n",
        "    r, g, b = [np.zeros_like(vis_parsing_anno, dtype=np.uint8) for _ in range(3)]\n",
        "\n",
        "    for y in range(0, h - h_step, h_step):\n",
        "        for x in range(0, w - w_step, w_step):\n",
        "            overlay_diagonal(y, x, 1, 1)  # top-left to bottom-right\n",
        "            overlay_diagonal(y, x + w_step, 1, -1)  # top-right to bottom-left\n",
        "\n",
        "    vis_im_bgr = cv2.cvtColor(cv2.cvtColor(vis_im, cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB)\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    weight_dis = 0.7\n",
        "    vis_im = cv2.addWeighted(vis_im_bgr, weight_dis, rgb, 1.0 - weight_dis, 0)\n",
        "\n",
        "    combined_image = np.hstack((original_vis_im, vis_im))\n",
        "\n",
        "    return combined_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyREnCMQWG5r",
        "outputId": "2c9eb081-111e-4eef-8333-4bb0b3d9d58b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from model import BiSeNet\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check for CUDA availability and set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "dspth='./'\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "n_classes = 19\n",
        "net = BiSeNet(n_classes=n_classes)\n",
        "net.to(device)\n",
        "net.load_state_dict(torch.load('weights.pth', map_location=torch.device(device)))\n",
        "net.eval()\n",
        "\n",
        "to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "with torch.no_grad():\n",
        "    grid_sizes = [100, 50, 25, 10]  # Define grid sizes\n",
        "\n",
        "    for image_path in os.listdir(dspth):\n",
        "        if image_path.lower().endswith(('.jpg', '.png')):\n",
        "          img = Image.open(osp.join(dspth, image_path))\n",
        "          image = img.resize((512, 512), Image.BILINEAR)\n",
        "          img = to_tensor(image)\n",
        "          img = torch.unsqueeze(img, 0)\n",
        "          img = img.to(device)\n",
        "          out = net(img)[0]\n",
        "          parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
        "\n",
        "          out_vid = cv2.VideoWriter('result.mp4', fourcc, 1.0, (1024, 512))\n",
        "\n",
        "          for grid in tqdm(grid_sizes):\n",
        "              vis_im = vis_parsing_maps_for_video(image, parsing, stride=1, grid_size=grid)\n",
        "              # Add the same image to the video for 2 seconds (given 1 FPS)\n",
        "              out_vid.write(vis_im)\n",
        "              out_vid.write(vis_im)\n",
        "\n",
        "        out_vid.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "iwfpuGxXkK2i",
        "outputId": "deb8daf8-cce5-4e72-c39f-c0af1b19c07c"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "video_path = \"result.mp4\"\n",
        "video_tag = f\"\"\"\n",
        "<video controls src=\"{video_path}\" width=\"1024\" height=\"512\"/>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(video_tag))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2DyzDfewG7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
